{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-02T10:21:14.680808Z","iopub.status.busy":"2024-09-02T10:21:14.680390Z","iopub.status.idle":"2024-09-02T10:21:15.773289Z","shell.execute_reply":"2024-09-02T10:21:15.772508Z","shell.execute_reply.started":"2024-09-02T10:21:14.680765Z"},"trusted":true},"outputs":[],"source":["import fitz  # PyMuPDF\n","\n","def extract_text_from_pdf(pdf_path, start_page):\n","    text = \"\"\n","    pdf_document = fitz.open(pdf_path)\n","    for page_num in range(start_page - 1, len(pdf_document)):\n","        page = pdf_document.load_page(page_num)\n","        text += page.get_text()\n","    return text\n","\n","pdf_path = '/kaggle/input/fa-manual/FA-manual.pdf'\n","start_page = 14  # Specify the starting page number\n","text = extract_text_from_pdf(pdf_path, start_page)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-02T10:22:19.686228Z","iopub.status.busy":"2024-09-02T10:22:19.685863Z","iopub.status.idle":"2024-09-02T10:23:00.702285Z","shell.execute_reply":"2024-09-02T10:23:00.701043Z","shell.execute_reply.started":"2024-09-02T10:22:19.686191Z"},"trusted":true},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","from chromadb import Client\n","import torch\n","# Initialize SentenceTransformer and Chroma client\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","client = Client()\n","collection = client.create_collection(name='first_aid_knowledge_base')\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = model.to(device)\n","\n","def generate_and_store_embeddings(text):\n","    chunks = text.split('\\n')  # Example chunking, adjust as necessary\n","    embeddings = model.encode(chunks)\n","    \n","    # Create lists for IDs, embeddings, and metadata\n","    ids = [str(i) for i in range(len(chunks))]\n","    metadata = [{'text': chunk} for chunk in chunks]\n","    \n","    # Add data to the collection\n","    collection.add(\n","        ids=ids,\n","        embeddings=embeddings.tolist(),  # Convert to list if needed\n","        metadatas=metadata\n","    )\n","\n","generate_and_store_embeddings(text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-02T10:23:00.704490Z","iopub.status.busy":"2024-09-02T10:23:00.703836Z","iopub.status.idle":"2024-09-02T10:23:05.537227Z","shell.execute_reply":"2024-09-02T10:23:05.536313Z","shell.execute_reply.started":"2024-09-02T10:23:00.704431Z"},"trusted":true},"outputs":[],"source":["import asyncio\n","import time\n","import re\n","from sentence_transformers import SentenceTransformer\n","from chromadb import Client\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","import nest_asyncio\n","\n","# Apply nest_asyncio to allow nested event loops\n","nest_asyncio.apply()\n","\n","# Initialize SentenceTransformer, Chroma client, and GPT-2 model\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","client = Client()\n","collection = client.get_collection('first_aid_knowledge_base')\n","\n","gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n","\n","async def retrieve_context_and_generate_response(query):\n","    \n","    # Encode the query\n","    query_embedding = model.encode([query])[0].tolist()\n","    \n","    # Query the Chroma collection\n","    results = collection.query(query_embeddings=[query_embedding], n_results=10)  # Adjust parameters as needed\n","    \n","    # Process results\n","    context_ = results['metadatas'][0]\n","    context = ''\n","    \n","    if context_:\n","        for item in context_:\n","            if 'text' in item:\n","                context += item['text'] + \" \"\n","\n","    # Generate a response using GPT-2 with the retrieved context\n","    input_text = f\"Based on the information: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n","    \n","    # Tokenize input text\n","    encoding = gpt2_tokenizer(input_text, return_tensors='pt', truncation=True, max_length=1024)\n","    inputs = encoding['input_ids']\n","    attention_mask = encoding.get('attention_mask', None)\n","    \n","    # Generate text\n","    outputs = gpt2_model.generate(\n","        inputs, \n","        attention_mask=attention_mask, \n","        max_length=400, \n","        num_return_sequences=1, \n","        no_repeat_ngram_size=2,\n","        temperature=0.7,\n","        top_p=0.9,\n","        top_k=50,\n","        num_beams=5,\n","        pad_token_id=gpt2_tokenizer.eos_token_id \n","    )\n","    \n","    response = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    response = ''.join(response.split('\\n\\n')[-1].split('.')[:-1])\n","    response = re.sub(r'\\d+', '', response)\n","    return response\n","\n","def determine_intent(user_input):\n","    emergency_keywords = [\"emergency\", \"urgent\", \"help\", \"immediate\", \"critical\"]\n","    message_keywords = [\"message\", \"leave a message\", \"note\", \"notify\", \"contact\"]\n","\n","    if any(keyword in user_input.lower() for keyword in emergency_keywords):\n","        return \"emergency\"\n","    elif any(keyword in user_input.lower() for keyword in message_keywords):\n","        return \"leave_message\"\n","    else:\n","        return \"unknown\"\n","\n","def needs_treatment_query(user_input):\n","    treatment_keywords = [\"treatment\", \"help with\", \"how to treat\", \"what to do\"]\n","    return any(keyword in user_input.lower() for keyword in treatment_keywords)\n","\n","async def chatbot():\n","    while True:\n","        user_input = input(\"How can I assist you? \").strip().lower()\n","        intent = determine_intent(user_input)\n","        \n","        if intent == \"emergency\":\n","            await handle_emergency()\n","            break  # End conversation after handling emergency\n","        elif intent == \"leave_message\":\n","            await leave_message()\n","            break  # End conversation after leaving a message\n","        else:\n","            print(\"I don’t understand that. Please specify if it is an emergency or if you want to leave a message for the doctor.\")\n","            # Continue the loop for another input\n","\n","async def handle_emergency():\n","    emergency_description = input(\"Please describe the emergency: \").strip().lower()\n","    \n","    if not needs_treatment_query(emergency_description):\n","        emergency_description = \"How to treat \" + emergency_description\n","    \n","    # Start the timer and the background generation task\n","    start_time = time.time()\n","    response_task = asyncio.create_task(retrieve_context_and_generate_response(emergency_description))\n","    \n","    await get_user_address(response_task, start_time)\n","\n","async def get_user_address(response_task, start_time):\n","    user_address = input(\"Please provide your address: \").strip()\n","    print(\"The doctor shall soon be reaching your location.\")\n","    \n","    await post_address_assistance(response_task, start_time)\n","\n","async def post_address_assistance(response_task, start_time):\n","    user_input = input(\"How may I assist you further? \").strip().lower()\n","    \n","    if any(word in user_input for word in [\"wait\", \"okay\", \"yes\", \"alright\"]):\n","        print(\"Thank you for your patience. Dr. Adrin will be with you shortly.\")\n","        return\n","\n","    \n","    elapsed_time = time.time() - start_time\n","    if elapsed_time<15:\n","        print(\"Just a moment...\")\n","    else:\n","        while elapsed_time < 15:\n","            elapsed_time = time.time() - start_time\n","            if elapsed_time >= 15:\n","                break\n","            await asyncio.sleep(1)\n","    \n","    if response_task.done():\n","        response = await response_task\n","        print(f\"“Don’t worry, please follow these steps, Dr. Adrin will be with you shortly”\\n\\n{response}\")\n","    else:\n","        print(\"Please hold a moment while we generate a response...\")\n","        response = await response_task\n","        print(f\"“Don’t worry, please follow these steps, Dr. Adrin will be with you shortly”\\n\\n{response}\")\n","\n","async def leave_message():\n","    user_message = input(\"Please leave your message for the doctor: \").strip()\n","    print(\"Your message has been recorded. The doctor will get back to you soon.\")\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-02T10:23:05.540311Z","iopub.status.busy":"2024-09-02T10:23:05.539992Z","iopub.status.idle":"2024-09-02T10:24:21.259946Z","shell.execute_reply":"2024-09-02T10:24:21.258998Z","shell.execute_reply.started":"2024-09-02T10:23:05.540276Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["How can I assist you?  I need help\n","Please describe the emergency:  My friend is having a sprain in his ankle\n","Please provide your address:  IIT Patna\n"]},{"name":"stdout","output_type":"stream","text":["The doctor shall soon be reaching your location.\n"]},{"name":"stdout","output_type":"stream","text":["How may I assist you further?  Please call the doctor at immediate\n"]},{"name":"stdout","output_type":"stream","text":["Please hold a moment while we generate a response...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a54aab2c226425cb1ddcfbad92f656b","version_major":2,"version_minor":0},"text/plain":["Batches:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["“Don’t worry, please follow these steps, Dr. Adrin will be with you shortly”\n","\n","Answer: If you have a sprain in your ankle, you may be able to help your friend heal by following the following steps:  Ask your doctor if he or she can help you  Tell him or her about your condition  Take a blood test  Call your local emergency room  Talk to a doctor  See a specialist  Have a physical exam  Go to the doctor's office  Get a CT scan  Make a note of the location of your injury  Write down your symptoms  Check your blood pressure  Look for any signs or symptoms of pain or swelling  If there is any swelling or pain, call your physician immediately  Be sure to talk to your family and friends  Keep in touch with your friends and family members  Do not take any medications  Don't drink alcohol  Stay hydrated  Sleep well  Drink plenty of water  Eat a healthy diet  Exercise regularly  Wear a good pair of shoes  Clean up after yourself  Give yourself time to rest  Relax and enjoy the day\n"]}],"source":["# Start the chatbot\n","asyncio.run(chatbot())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5628559,"sourceId":9296481,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
